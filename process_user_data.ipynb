{
 "metadata": {
  "name": "",
  "signature": "sha256:aac3274eab5b94c8ea7f862dfa040f9efa8bd5f8eac5a3f7e998da4f9b6de618"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Data Collection\n",
      "\n",
      "This notebook assembles the data that we process into one single CSV that is user focused and contains all metadata about the users themselves (age, reputation, upvotes/downvotes) as well as their behavior (questions, answers, accepted answers and tags.)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os, glob\n",
      "import xml.etree.ElementTree as ET\n",
      "import csv\n",
      "import simplejson as json\n",
      "import base64\n",
      "import bson\n",
      "import pandas as pd\n",
      "import time\n",
      "import datetime as dt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "userids = []\n",
      "questions = {}\n",
      "answers = {}\n",
      "accepted_answers = {}\n",
      "accepted_answers_flag = {}\n",
      "question_tags = {} # key is question id\n",
      "user_tags = {} # key is userid"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Processing methods\n",
      "\n",
      "These methods process our data. They aggregate the questions & answers, and are able to write them out to disk.\n",
      "\n",
      "See comment directly above the methods themselves."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Replace the tags in the rows, which are html with just a \n",
      "# comma delimited list.\n",
      "def parseTags(tags):\n",
      "    return tags.replace(\"><\",\",\").replace(\"<\",\"\").replace(\">\",\"\").split(\",\")\n",
      "\n",
      "# Assemble the posts that are questions. Also cache the id of the accepted\n",
      "# answer so that we can separate it later when aggregating answers. Also\n",
      "# assemble the tags per question.\n",
      "def processQuestions( f ):\n",
      "    tree = ET.parse(f)\n",
      "    posts = tree.getroot().getchildren()\n",
      "    \n",
      "    for post in posts:\n",
      "        user = post.get('OwnerUserId')\n",
      "        tags = post.get('Tags')\n",
      "        \n",
      "        # increment question counter\n",
      "        key = str(user)\n",
      "        userids.append(key)\n",
      "        \n",
      "        if (key in questions):\n",
      "            questions[key] = questions[key] + 1\n",
      "        else:\n",
      "            questions[key] = 1\n",
      "        \n",
      "        \n",
      "        # mark answer as accepted.\n",
      "        answer = post.get('AcceptedAnswerId')\n",
      "        accepted_answers_flag[answer] = 1\n",
      "        \n",
      "        # process tags - just save for every question its tags. When \n",
      "        # we get to an accepted answer next time, we will add them up.\n",
      "        tags = parseTags(tags)\n",
      "        question_tags[post.get('Id')] = tags\n",
      "\n",
      "# Aggregate posts that are answers. Separate them into answers that were\n",
      "# accepted versus those that were not. Use our question -> tag map to resolve\n",
      "# which users are experts on what subjets. The assumption is that if you answer\n",
      "# a question with certain tags and that answer is accepted, then you are\n",
      "# familiar with those tags used for the original question.\n",
      "def processAnswers( f ):\n",
      "    tree = ET.parse(f)\n",
      "    posts = tree.getroot().getchildren()\n",
      "    \n",
      "    for post in posts:\n",
      "        user = post.get('OwnerUserId')\n",
      "        key = str(user)\n",
      "        userids.append(key)\n",
      "        \n",
      "        postId = post.get('Id')\n",
      "        \n",
      "        # count an answer as an accepted answer if it's flagged as so\n",
      "        # otherwise, just count it as an answer.\n",
      "        if postId in accepted_answers_flag:\n",
      "            \n",
      "            # increment counter\n",
      "            if key in accepted_answers:\n",
      "                accepted_answers[key] = accepted_answers[key] + 1\n",
      "            else:\n",
      "                accepted_answers[key] = 1\n",
      "                \n",
      "            tags = question_tags[post.get('ParentId')]\n",
      "            if tags:\n",
      "                if user not in user_tags:\n",
      "                    user_tags[user] = {}\n",
      "                    \n",
      "                for tag in tags:\n",
      "                    if tag in user_tags[user]:\n",
      "                        user_tags[user][tag] = user_tags[user][tag] + 1\n",
      "                    else:\n",
      "                        user_tags[user][tag] = 1           \n",
      "                \n",
      "        else:\n",
      "            if key in answers:\n",
      "                answers[key] = answers[key] + 1\n",
      "            else:\n",
      "                answers[key] = 1\n",
      "\n",
      "\n",
      "# Write out the metadata for a user which includes:\n",
      "# Number of questions asked\n",
      "# Number of answers provided that were not accepted\n",
      "# Number of accepted answers\n",
      "# Tags and their counts\n",
      "def writeCSV( filename ):\n",
      "    csv.register_dialect('escaped', escapechar='\\\\', doublequote=False, quoting=csv.QUOTE_NONE)\n",
      "    csv.register_dialect('singlequote', quotechar=\"'\", quoting=csv.QUOTE_ALL)\n",
      "    \n",
      "    with open(filename, 'w') as f:  # Just use 'w' mode in 3.x\n",
      "        csfile = csv.writer(f, delimiter=',', quotechar='\\'')\n",
      "        csfile.writerow([\"id\", \"question_count\", \"answer_count\", \"accepted_answer_count\", \"tags\"])\n",
      "        for userid in set(userids):\n",
      "            # build tuple\n",
      "            tuple = [userid]\n",
      "            if userid in questions:\n",
      "                tuple.append(questions[userid])\n",
      "            else:\n",
      "                tuple.append(0)\n",
      "            \n",
      "            if userid in answers:\n",
      "                tuple.append(answers[userid])\n",
      "            else:\n",
      "                tuple.append(0)\n",
      "                \n",
      "            if userid in accepted_answers:\n",
      "                tuple.append(accepted_answers[userid])\n",
      "            else:\n",
      "                tuple.append(0)\n",
      "                \n",
      "            if userid in user_tags:\n",
      "                _tags = \"\"\n",
      "                for tag in user_tags[userid].keys():\n",
      "                    _tags = _tags + tag + \"|\" + str(user_tags[userid][tag]) + \",\"\n",
      "                    \n",
      "                tuple.append(_tags[:-1])\n",
      "            else:\n",
      "                tuple.append(\"\")\n",
      "                \n",
      "            csfile.writerow(tuple)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Processing Phase\n",
      "\n",
      "Process our questions"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "for f in glob.glob(\"stackexchange/splitposts/data/*_questions\"):\n",
      "    processQuestions(f)\n",
      "    print \"Processed \" + f"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Processed stackexchange/splitposts/data/_Posts_aa_questions\n",
        "Processed stackexchange/splitposts/data/_Posts_ab_questions"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed stackexchange/splitposts/data/_Posts_ac_questions"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed stackexchange/splitposts/data/_Posts_ad_questions"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed stackexchange/splitposts/data/_Posts_ae_questions"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed stackexchange/splitposts/data/_Posts_af_questions"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed stackexchange/splitposts/data/_Posts_ag_questions"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed stackexchange/splitposts/data/_Posts_ah_questions"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed stackexchange/splitposts/data/_Posts_ai_questions"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed stackexchange/splitposts/data/_Posts_aj_questions"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed stackexchange/splitposts/data/_Posts_ak_questions"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed stackexchange/splitposts/data/_Posts_al_questions"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed stackexchange/splitposts/data/_Posts_am_questions"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed stackexchange/splitposts/data/_Posts_an_questions"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed stackexchange/splitposts/data/_Posts_ao_questions"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed stackexchange/splitposts/data/_Posts_ap_questions"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed stackexchange/splitposts/data/_Posts_aq_questions"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed stackexchange/splitposts/data/_Posts_ar_questions"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed stackexchange/splitposts/data/_Posts_as_questions"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed stackexchange/splitposts/data/_Posts_at_questions"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed stackexchange/splitposts/data/_Posts_au_questions"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed stackexchange/splitposts/data/_Posts_av_questions"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed stackexchange/splitposts/data/_Posts_aw_questions"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed stackexchange/splitposts/data/_Posts_ax_questions"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed stackexchange/splitposts/data/_Posts_ay_questions"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed stackexchange/splitposts/data/_Posts_az_questions"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed stackexchange/splitposts/data/_Posts_ba_questions\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Process our answers (note this relies on structures established during question parsing.)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "for f in glob.glob(\"stackexchange/splitposts/data/*_answers\"):\n",
      "    processAnswers(f)\n",
      "    print \"Processed \" + f"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Processed stackexchange/splitposts/data/_Posts_aa_answers\n",
        "Processed stackexchange/splitposts/data/_Posts_ab_answers"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed stackexchange/splitposts/data/_Posts_ac_answers"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed stackexchange/splitposts/data/_Posts_ad_answers"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed stackexchange/splitposts/data/_Posts_ae_answers"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed stackexchange/splitposts/data/_Posts_af_answers"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed stackexchange/splitposts/data/_Posts_ag_answers"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed stackexchange/splitposts/data/_Posts_ah_answers"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed stackexchange/splitposts/data/_Posts_ai_answers"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed stackexchange/splitposts/data/_Posts_aj_answers"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed stackexchange/splitposts/data/_Posts_ak_answers"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed stackexchange/splitposts/data/_Posts_al_answers"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed stackexchange/splitposts/data/_Posts_am_answers"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed stackexchange/splitposts/data/_Posts_an_answers"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed stackexchange/splitposts/data/_Posts_ao_answers"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed stackexchange/splitposts/data/_Posts_ap_answers"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed stackexchange/splitposts/data/_Posts_aq_answers"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed stackexchange/splitposts/data/_Posts_ar_answers"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed stackexchange/splitposts/data/_Posts_as_answers"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed stackexchange/splitposts/data/_Posts_at_answers"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed stackexchange/splitposts/data/_Posts_au_answers"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed stackexchange/splitposts/data/_Posts_av_answers"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed stackexchange/splitposts/data/_Posts_aw_answers"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed stackexchange/splitposts/data/_Posts_ax_answers"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed stackexchange/splitposts/data/_Posts_ay_answers"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed stackexchange/splitposts/data/_Posts_az_answers"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed stackexchange/splitposts/data/_Posts_ba_answers\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Write out the results to a csv on the file system."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "writeCSV( \"userMetadata.csv\" )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Building final data frame\n",
      "\n",
      "In the following sections we load our previously extracted data, as well as our user xml data and combine it into one data frame. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Create a dictionary of user questions, answer and accepted_answers. (answers\n",
      "# do not include accepted_answers).\n",
      "\n",
      "user_posts = {}\n",
      "from StringIO import StringIO\n",
      "import ast\n",
      "with open( 'userMetadata.csv', 'rb' ) as f:\n",
      "    \n",
      "    csv.register_dialect('escaped', escapechar='\\\\', doublequote=False, quoting=csv.QUOTE_NONE)\n",
      "    csv.register_dialect('singlequote', quotechar=\"'\", quoting=csv.QUOTE_ALL)\n",
      "    \n",
      "    reader = csv.reader(f, delimiter=',', quotechar='\\'')\n",
      "    i = 0\n",
      "    for row in reader:\n",
      "        if (i > 0):\n",
      "            userid = row[0]\n",
      "            q = int(row[1])\n",
      "            a = int(row[2])\n",
      "            aa = int(row[3])\n",
      "            \n",
      "            tags = row[4].split(\",\")\n",
      "            _tags = {}\n",
      "            if len(row[4]) > 0 and len(tags) > 0:\n",
      "                \n",
      "                for t in tags:\n",
      "                    parts = t.split(\"|\")\n",
      "                    if len(parts) == 2:\n",
      "                        _tags[parts[0]] = int(parts[1])\n",
      "                \n",
      "            user_posts[userid] = [q,a,aa,_tags]\n",
      "        i = i + 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Parse Users.xml to extract user details. Combine with above computed\n",
      "# user post behaviour.\n",
      "tree = ET.parse('Users_sample.xml')\n",
      "users = tree.getroot().getchildren()\n",
      "    \n",
      "# Create dataframe\n",
      "def createTuples( users ):\n",
      "    tuples = []\n",
      "    counter = 0\n",
      "\n",
      "    for user in users:         \n",
      "        if user.get('Age'):      \n",
      "            \n",
      "            counter = counter + 1\n",
      "                \n",
      "            creationDate = dt.datetime.fromtimestamp(\n",
      "                time.mktime(\n",
      "                    time.strptime(user.get('CreationDate')[:-4], \"%Y-%m-%dT%H:%M:%S\")\n",
      "                ))\n",
      "            lastAccessDate = dt.datetime.fromtimestamp(\n",
      "                time.mktime(\n",
      "                    time.strptime(user.get('LastAccessDate')[:-4], \"%Y-%m-%dT%H:%M:%S\")\n",
      "                ))\n",
      "        \n",
      "            rep = int(user.get('Reputation'))\n",
      "            timeOnSite = (lastAccessDate - creationDate).days\n",
      "            userid = user.get('Id')\n",
      "\n",
      "            q = 0\n",
      "            a = 0\n",
      "            aa = 0\n",
      "            tags = {}\n",
      "            if userid in user_posts:\n",
      "                q = user_posts[userid][0]\n",
      "                a = user_posts[userid][1]\n",
      "                aa = user_posts[userid][2]\n",
      "                tags = user_posts[userid][3]\n",
      "                \n",
      "            if (timeOnSite > 0):\n",
      "                tuples.append(\n",
      "                    (userid,\n",
      "                     int(user.get('Age')), \n",
      "                     int(user.get('UpVotes')),\n",
      "                     int(user.get('DownVotes')),\n",
      "                     rep,\n",
      "                     # '2008-08-26T00:16:53.810'\n",
      "                     creationDate,\n",
      "                     lastAccessDate,\n",
      "                     timeOnSite,\n",
      "                     (dt.datetime.now()-lastAccessDate).days,\n",
      "                     rep / float(timeOnSite),\n",
      "                     q,\n",
      "                     a,\n",
      "                     aa,\n",
      "                     tags)\n",
      "                )\n",
      "    print(\"Users found\", counter, \"out of\", len(users))\n",
      "    return tuples\n",
      "\n",
      "def createDataFrame( users ):\n",
      "    df = pd.DataFrame( createTuples( users ), \n",
      "                      columns=[\"UserId\", \"Age\", \"UpVotes\", \"DownVotes\", \"Reputation\", \n",
      "                               \"CreationDate\", \"LastAccessDate\", \"TimeOnSite\", \"SinceLastAccess\",\n",
      "                               \"RepOverTimeCoeff\", \"Questions\", \"Answers\", \"Accepted_Answers\", \"Tags\"])\n",
      "    return df\n",
      "\n",
      "df = createDataFrame( users )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "('Users found', 372766, 'out of', 373188)\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Write out our user data to a csv"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.to_csv('all_user_data.csv', sep=\",\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Check loading of users into a dataframe:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fd = pd.DataFrame.from_csv('all_user_data.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## All done!\n",
      "\n",
      "When needing to process the user data, simply load your data like so:\n",
      "\n",
      "`fd = pd.DataFrame.from_csv('all_user_data.csv')`"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}